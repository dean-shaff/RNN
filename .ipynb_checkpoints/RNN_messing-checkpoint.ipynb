{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time creating character mapping and pickling: 1.9495 sec\n",
      "Time creating k map 3.319 sec\n",
      "Time creating arrays: 1.948 sec\n"
     ]
    }
   ],
   "source": [
    "from character_mapping import Character_Map \n",
    "import theano \n",
    "import theano.tensor as T\n",
    "import numpy as np \n",
    "\n",
    "text_test = './../texts/melville.txt'\n",
    "char_map_obj = Character_Map(text_test,'mapping.dat',overwrite=True, break_line=None)\n",
    "char_map_obj.k_map()\n",
    "x_, y_, shared_x, shared_y = char_map_obj.gen_x_and_y(filename=None)\n",
    "\n",
    "# print(shared_y.get_value().shape[1])\n",
    "nh = 100\n",
    "nx = len(char_map_obj.unique_char)\n",
    "ny = nx "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import theano \n",
    "import theano.tensor as T \n",
    "import numpy as np \n",
    "from character_mapping import Character_Map\n",
    "import time\n",
    "try:\n",
    "\timport cPickle as pickle\n",
    "except:\n",
    "\timport pickle\n",
    "\n",
    "class RNN(object):\n",
    "\n",
    "\tdef __init__(self, nh, nx, ny):\n",
    "\t\t\"\"\"\n",
    "\t\tThis is only set up for a single hidden layer \n",
    "\t\targs:\n",
    "\t\t\tnh is size of hidden layer vector \n",
    "\t\t\tnx is the size of the input vector \n",
    "\t\t\tny is the size of the output vector (ny = nx in character example)\n",
    "\t\t\"\"\"\n",
    "\t\t\n",
    "\t\t# self.emb = theano.shared(name='embeddings',\n",
    "\t\t# \t\t\t\t\t\t value=0.2 * numpy.random.uniform(-1.0, 1.0,\n",
    "\t\t# \t\t\t\t\t\t (ne+1, de))\n",
    "\t\t# \t\t\t\t\t\t # add one for padding at the end\n",
    "\t\t# \t\t\t\t\t\t .astype(theano.config.floatX))\n",
    "\n",
    "\t\tself.wx = theano.shared(name='wx',\n",
    "\t\t\t\t\t\t\t\tvalue=0.2 * np.random.uniform(-1.0, 1.0,\n",
    "\t\t\t\t\t\t\t\t(nx, nh))\n",
    "\t\t\t\t\t\t\t\t.astype(theano.config.floatX)) #input weights\n",
    "\n",
    "\t\tself.wh = theano.shared(name='wh',\n",
    "\t\t\t\t\t\t\t\tvalue=0.2 * np.random.uniform(-1.0, 1.0,\n",
    "\t\t\t\t\t\t\t\t(nh, nh))\n",
    "\t\t\t\t\t\t\t\t.astype(theano.config.floatX)) #hidden layer weights\n",
    "\n",
    "\t\tself.wy = theano.shared(name='wy',\n",
    "\t\t\t\t\t\t\t   value=0.2 * np.random.uniform(-1.0, 1.0,\n",
    "\t\t\t\t\t\t\t   (nh, ny))\n",
    "\t\t\t\t\t\t\t   .astype(theano.config.floatX)) #output weights\n",
    "\t\t\n",
    "\t\tself.bh = theano.shared(name='bh',\n",
    "\t\t\t\t\t\t\t\tvalue=np.zeros(nh,\n",
    "\t\t\t\t\t\t\t\tdtype=theano.config.floatX)) #hidden layer bias\n",
    "\t\t\n",
    "\t\tself.by = theano.shared(name='b',\n",
    "\t\t\t\t\t\t\t   value=np.zeros(ny,\n",
    "\t\t\t\t\t\t\t   dtype=theano.config.floatX)) #output layer bias\n",
    "\t\t\n",
    "\t\tself.h0 = theano.shared(name='h0',\n",
    "\t\t\t\t\t\t\t\tvalue=np.zeros(nh,\n",
    "\t\t\t\t\t\t\t\tdtype=theano.config.floatX)) #initial h vector \n",
    "\n",
    "\t\tself.sequence_length = 15\n",
    "\n",
    "\tdef feed_through(self,x,h_tm1):\n",
    "\t\t\"\"\"\n",
    "\t\tt_step is the current time step. If t_step == 0, then we use self.h0\n",
    "\t\tto feed through net.\n",
    "\t\tbasically copied from the theano tutorial\n",
    "\t\t\"\"\"\n",
    "\t\th = T.tanh(T.dot(x,self.wx) + T.dot(h_tm1, self.wh) + self.bh)\n",
    "\n",
    "\t\ty_hat = self.by + T.dot(h,self.wy)\n",
    "\n",
    "\t\ty_guess = T.nnet.softmax(y_hat) \n",
    "\n",
    "\t\treturn h, y_guess\n",
    "\t\n",
    "\tdef loss(self,x,y):\n",
    "\t\t\"\"\"\n",
    "\t\targs:\n",
    "\t\t\t- x is a vector containing the first character of a sequence \n",
    "\t\t\t- y is a vector containing the last character of the sequence \n",
    "\t\t\t\n",
    "\t\t***assuming constance sequence length****\n",
    "\t\t\"\"\"\n",
    "\t\t# y = y[-1]\n",
    "\n",
    "\t\t# y_intermediate, h = self.feed_through_dean(x,self.h0)\n",
    "\t\t# y_total = y_intermediate\n",
    "\t\t# for i in xrange(1,self.sequence_length):\n",
    "\t\t# \ty_intermediate, h = self.feed_through_dean(y_intermediate,h)\n",
    "\t\t# \ty_total += y_intermediate\n",
    "\n",
    "\t\t[h, s], _ = theano.scan(fn=self.feed_through,\n",
    "\t\t\t\t\t\tsequences=x,\n",
    "\t\t\t\t\t\toutputs_info=[self.h0,None])\n",
    "\t\t\t\t\t\t# n_steps=self.sequence_length)\n",
    "\t\t\n",
    "\t\t# return -T.mean(T.log(p_y_given_x_sentence)[T.arange(y.shape[0]), y])\n",
    "\t\treturn -T.mean(T.log(s)[T.arange(y.shape[0]), y])\n",
    "\n",
    "\tdef save_param(self,pickle_file):\n",
    "\n",
    "\t\tpickle_me = {\n",
    "\t\t\t\t\t'param':[self.wx, self.wh, self.wy, self.bh, self.by, self.h0]\n",
    "\t\t}\n",
    "\n",
    "\t\tpickle.dump( pickle_me, open(pickle_file, 'wb') )\n",
    "\n",
    "\tdef load_param(self,pickle_file):\n",
    "\n",
    "\t\tpickle_me = pickle.load(open(pickle_file,'rb'))\n",
    "\n",
    "\t\tparam = pickle_me['param']\n",
    "\n",
    "\t\tself.wx, self.wh, self.wy, self.bh, self.by, self.h0 = param\n",
    "\n",
    "\tdef train(self,training_data,learning_rate,n_epochs,mini_batch_size):\n",
    "\t\t\"\"\"\n",
    "\t\targs:\n",
    "\t\t\t- training_data: inputs with ideal \n",
    "\t\t\"\"\"\n",
    "\t\t# self.char_sequence_length = char_sequence_length\n",
    "\t\ttrain_x, train_y = training_data\n",
    "\t\t# train_y = T.cast(train_y,'int32')\n",
    "\t\ttrain_size_total = train_x.get_value(borrow=True).shape[0]\n",
    "\n",
    "\t\t# n_train = len(train_x)\n",
    "\t\t# print(train_size_total, n_train)\n",
    "\t\tn_train_batches = train_size_total/mini_batch_size\n",
    "\n",
    "\t\tx = T.matrix('x')\n",
    "\t\ty = T.imatrix('y')\n",
    "\t\tindex = T.iscalar()\n",
    "\n",
    "\t\tcost = self.loss(x,y)\n",
    "\t\tparams = [self.wx, self.wh, self.wy, self.bh, self.by, self.h0]\n",
    "\t\tgrads = T.grad(cost,params)\n",
    "\t\tupdates = [(param, param-learning_rate*grad) for param, grad in zip(params,grads)]\n",
    "\n",
    "\t\ttrain_model1 = theano.function(\n",
    "\t\t\tinputs = [x,y],\n",
    "\t\t\toutputs = cost,\n",
    "\t\t\tupdates = updates\n",
    "\t\t)\n",
    "\t\tprint(\"function compiled\")\n",
    "# \t\ttrain_model1(train_x.get_value()[0:2],train_y.get_value()[0:2])\n",
    "\t\t# train_model = theano.function(\n",
    "\t\t# \tinputs = [index],\n",
    "\t\t# \toutputs = cost,\n",
    "\t\t# \tupdates = updates,\n",
    "\t\t# \tgivens = {\n",
    "\t\t# \t\tx: train_x[index*mini_batch_size: (index+1)*mini_batch_size],\n",
    "\t\t# \t\ty: train_y[index*mini_batch_size: (index+1)*mini_batch_size] \n",
    "\t\t# \t}\n",
    "\t\t# )\n",
    "\t\t# print(\"Function compiled\")\n",
    "\t\t# for i in xrange(n_epochs):\n",
    "\t\t# \tt1 = time.time()\n",
    "\t\t# \tfor index in xrange(n_train_batches):\n",
    "\t\t# \t\ttrain_model(index)\n",
    "\t\t# \t\t# print(\"Minibatch done\")\n",
    "\t\t# \tprint(\"Epoch number {}, took {:.3f} sec\".format(i,time.time()-t1))\n",
    "\t\t# \tif i % 5 == 0:\n",
    "\t\t# \t\tt2 = time.time()\n",
    "\t\t# \t\tself.save_param(\"param_epoch{}.dat\".format(i))\n",
    "\t\t# \t\tprint(\"Pickling epoch number {} took {:.3f} sec\".format(i, time.time()-t2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.01091557  0.01346954  0.01023326 ...,  0.01117334  0.00918349\n",
      "    0.01048125]]\n",
      "\n",
      " [[ 0.01185487  0.00872138  0.01160469 ...,  0.01344216  0.01319988\n",
      "    0.00789976]]\n",
      "\n",
      " [[ 0.01562081  0.01086014  0.01994807 ...,  0.01426068  0.01843997\n",
      "    0.00894905]]\n",
      "\n",
      " ..., \n",
      " [[ 0.00699087  0.02011978  0.01191004 ...,  0.00674438  0.00590327\n",
      "    0.00818914]]\n",
      "\n",
      " [[ 0.02325227  0.01286179  0.00688772 ...,  0.00643754  0.01449506\n",
      "    0.00492894]]\n",
      "\n",
      " [[ 0.01275721  0.01069187  0.01666327 ...,  0.01197606  0.01197785\n",
      "    0.00748668]]]\n"
     ]
    }
   ],
   "source": [
    "trainer = RNN(nh,nx,ny)\n",
    "\n",
    "x = T.matrix('x')\n",
    "y = T.imatrix('y')\n",
    "\n",
    "[h,s], _= theano.scan(fn=trainer.feed_through,\n",
    "                     sequences=x,\n",
    "                     outputs_info=[trainer.h0, None])\n",
    "                     #non_sequences = [trainer.wx,trainer.wh,trainer.wy,trainer.bh,trainer.by])\n",
    "# foo = T.log(s)\n",
    "# fn1 = theano.function([x],s)\n",
    "# print(fn1(shared_x.get_value()[0]))\n",
    "    \n",
    "error = T.log(s)[T.arange(y.shape[0]),y]\n",
    "\n",
    "fn = theano.function([x,y],error)\n",
    "\n",
    "fn(shared_x.get_value()[0],shared_y.get_value()[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
